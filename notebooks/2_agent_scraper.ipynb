{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2960d148",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import re\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "16e94267",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://www.ebay.co.uk/sch/i.html?_dcat=66700&_fsrp=1&rt=nc&_from=R40&LH_PrefLoc=1&_ipg=240&LH_ItemCondition=4&LH_Sold=1&_nkw=pram+buggy+pushchair+stroller&_sacat=0&LH_BIN=1&_sop=12&LH_SellerType=1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb334aa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def scrape_ebay_sold_items(url):\n",
    "    \"\"\"\n",
    "    Final corrected version using su-card-container__content containers\n",
    "    \"\"\"\n",
    "    headers = {'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36'}\n",
    "\n",
    "    try:\n",
    "        response = requests.get(url, headers=headers, timeout=15)\n",
    "        response.raise_for_status()\n",
    "        soup = BeautifulSoup(response.content, 'html.parser')\n",
    "\n",
    "        print(\"Extracting from su-card-container__content containers...\")\n",
    "\n",
    "        # Find the correct item containers\n",
    "        item_containers = soup.find_all('div', class_='su-card-container__content')\n",
    "        print(f\"Found {len(item_containers)} item containers\")\n",
    "\n",
    "        extracted_items = []\n",
    "\n",
    "        for i, container in enumerate(item_containers):\n",
    "            item_data = extract_from_container(container)\n",
    "\n",
    "            if item_data:\n",
    "                extracted_items.append(item_data)\n",
    "\n",
    "                # Show progress for first few items\n",
    "                if len(extracted_items) <= 5:\n",
    "                    print(f\"  âœ“ Item {len(extracted_items)}: {item_data['description'][:40]}... - Â£{item_data['price_sold']}\")\n",
    "\n",
    "        # Remove duplicates (if any)\n",
    "        df = pd.DataFrame(extracted_items)\n",
    "\n",
    "        if not df.empty:\n",
    "            # Remove exact duplicates\n",
    "            df = df.drop_duplicates(subset=['description', 'price_sold', 'date_sold'])\n",
    "            df = df.reset_index(drop=True)\n",
    "\n",
    "            print(f\"Final dataset: {len(df)} unique items\")\n",
    "\n",
    "        return df\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error: {e}\")\n",
    "        return pd.DataFrame(columns=['date_sold', 'description', 'price_sold'])\n",
    "\n",
    "def extract_from_container(container):\n",
    "    \"\"\"\n",
    "    Extract complete item data from su-card-container__content\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Find price within this container\n",
    "        price_elem = container.find('span', class_='s-card__price')\n",
    "        if not price_elem:\n",
    "            return None\n",
    "\n",
    "        price_text = price_elem.get_text().strip()\n",
    "\n",
    "        # Skip price ranges\n",
    "        if 'to' in price_text.lower():\n",
    "            return None\n",
    "\n",
    "        price_match = re.search(r'Â£([\\d,]+\\.?\\d*)', price_text)\n",
    "        if not price_match:\n",
    "            return None\n",
    "\n",
    "        price_sold = float(price_match.group(1).replace(',', ''))\n",
    "\n",
    "        # Find sold date within this container\n",
    "        date_elem = container.find('span', string=re.compile(r'sold.*\\d+.*\\w+.*\\d{4}', re.I))\n",
    "        if not date_elem:\n",
    "            return None\n",
    "\n",
    "        date_text = date_elem.get_text().strip()\n",
    "        date_match = re.search(r'sold\\s+(\\d{1,2}\\s+\\w+\\s+\\d{4})', date_text, re.I)\n",
    "        if not date_match:\n",
    "            return None\n",
    "\n",
    "        try:\n",
    "            date_sold = datetime.strptime(date_match.group(1), '%d %b %Y').date()\n",
    "        except:\n",
    "            return None\n",
    "\n",
    "        # Find description within this container\n",
    "        desc_elem = container.find('a', href=re.compile(r'/itm/'))\n",
    "        if not desc_elem:\n",
    "            return None\n",
    "\n",
    "        description = desc_elem.get_text().strip()\n",
    "\n",
    "        # Validate description (should be substantial and item-specific)\n",
    "        if not description or len(description) < 5:\n",
    "            return None\n",
    "\n",
    "        return {\n",
    "            'date_sold': date_sold,\n",
    "            'description': description,\n",
    "            'price_sold': price_sold\n",
    "        }\n",
    "\n",
    "    except Exception:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "591a2530",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the data\n",
    "df = scrape_ebay_sold_items(url)\n",
    "\n",
    "if not df.empty:\n",
    "    print(f\"Dataset summary:\")\n",
    "    print(f\"  Total items: {len(df)}\")\n",
    "    print(f\"  Date range: {df['date_sold'].min()} to {df['date_sold'].max()}\")\n",
    "    print(f\"  Price range: Â£{df['price_sold'].min():.2f} to Â£{df['price_sold'].max():.2f}\")\n",
    "\n",
    "    # Save final results\n",
    "    df.to_csv('ebay_sold_items_final.csv', index=False)\n",
    "    print(f\"\\nðŸ’¾ Saved final dataset to 'ebay_sold_items_final.csv'\")\n",
    "\n",
    "else:\n",
    "    print(\"âŒ Extraction failed\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "instacart-analysis-demonstration",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
